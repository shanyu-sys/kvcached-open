# Multi-LLM Benchmark Configuration

# Benchmark settings
benchmark:
  start_timestamp: "2025-08-07 00:00:00.000000" # start timestamp of the trace, this will be ignored
  end_timestamp: "2025-08-08 01:00:00.000000" # end timestamp of the trace
  slowdown_factor: 1 # a value of 0.1 means the replay is 10 times faster.
  torch_master_addr: "localhost" # master address for torch distributed communication
  torch_master_port: "29500" # default port for torch distributed communication
  status_interval: 60 # benchmark status update interval in seconds
  gpu_id: 3

# Instance configurations
instances:
  - name: "Qwen3-0.6B"
    model_name: "Qwen/Qwen3-0.6B"
    port: 30031
    trace_file: null
    trace_model_filter: "Qwen3-0.6B_20250607"
    model_path: null  # Set to null to use model_name, or specify a local path to use offline models.

  - name: "Llama-3.2-1B"
    model_name: "meta-llama/Llama-3.2-1B"
    port: 30032
    trace_file: null
    trace_model_filter: "Llama-3.2-1B_20250607"
    model_path: null

  - name: "gemma-2-2b-it"
    model_name: "google/gemma-2-2b-it"
    port: 30033
    trace_file: null
    trace_model_filter: "gemma-2-2b-it_2025-08-13"
    model_path: null

  - name: "Llama-3.2-3B"
    model_name: "meta-llama/Llama-3.2-3B"
    port: 30034
    trace_file: null
    trace_model_filter: "Llama-3.2-3B_20250607"
    model_path: null

  - name: "Qwen3-4B"
    model_name: "Qwen/Qwen3-4B"
    port: 30035
    trace_file: null
    trace_model_filter: "Qwen3-4B_20250529"
    model_path: null  # Set to null to use model_name, or specify a local path to use offline models.

  - name: "Mistral-7B-Instruct-v0.2"
    model_name: "mistralai/Mistral-7B-Instruct-v0.2"
    port: 30036
    trace_file: null
    trace_model_filter: "Mistral-7B-Instruct-v0.2_2025-08-13"
    model_path: null

  - name: "Llama-3.1-8B-Instruct"
    model_name: "meta-llama/Llama-3.1-8B-Instruct"
    port: 30037
    trace_file: null
    trace_model_filter: "Llama-3.1-8B-Instruct_latest"
    model_path: null

  - name: "Mistral-Nemo-Instruct-2407"
    model_name: "mistralai/Mistral-Nemo-Instruct-2407"
    port: 30038
    trace_file: null
    trace_model_filter: "Mistral-Nemo-Instruct-2407_preview"
    model_path: null


